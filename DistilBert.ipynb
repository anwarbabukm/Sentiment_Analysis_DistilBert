{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "DistilBert_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XryH1WdBtWU-eFoIb7ZTxnHMxhoq2eAv",
      "authorship_tag": "ABX9TyODiGnOfHKcQ9Ad+znHt3PI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d9ae97b01d54e8997d32c6896af9091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a5e0b7167e94cadad7e8d4a91631a4a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54640b02220f428d97cbc59ec1c963b3",
              "IPY_MODEL_6d1e47e965cc475ca3a110ecb3929f32"
            ]
          }
        },
        "3a5e0b7167e94cadad7e8d4a91631a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54640b02220f428d97cbc59ec1c963b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4750650e23554a08a9bd03086ffad46d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb8962a4fed84bbbba3d8341931e31c3"
          }
        },
        "6d1e47e965cc475ca3a110ecb3929f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a6619e55738480db54c616a4ede5d16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb69f336c3d242029754a1ed59d7131b"
          }
        },
        "4750650e23554a08a9bd03086ffad46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb8962a4fed84bbbba3d8341931e31c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a6619e55738480db54c616a4ede5d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb69f336c3d242029754a1ed59d7131b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4886ed8d25b449a48cf4b8304f196b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_545bbd06a0bc415ea33e7eb31ea66b20",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c72ad7dad744654b4754f1dbae07165",
              "IPY_MODEL_3e34be735492454f9bdceb42608540a3"
            ]
          }
        },
        "545bbd06a0bc415ea33e7eb31ea66b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c72ad7dad744654b4754f1dbae07165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_59941234d67d4c69b015b339f458964e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75b871e233ff4f47b0ccc6314887760d"
          }
        },
        "3e34be735492454f9bdceb42608540a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00e6eca065a542a5a4827858bbe21502",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 1.28kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5629040d942e46cd96aafdb98e0cb2da"
          }
        },
        "59941234d67d4c69b015b339f458964e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75b871e233ff4f47b0ccc6314887760d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00e6eca065a542a5a4827858bbe21502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5629040d942e46cd96aafdb98e0cb2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a13adf2f1e6427b87d570f10fe7de89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffd443a30f454ee1b3e7fd5487c3270f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eed5ead0b8b14fc6bf1894dbcdb4f986",
              "IPY_MODEL_4d21ad34fe434f8e8fd1479eb6f6ddc2"
            ]
          }
        },
        "ffd443a30f454ee1b3e7fd5487c3270f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eed5ead0b8b14fc6bf1894dbcdb4f986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1000130521cb4726b2943cacc6b4e3a9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dce0783e470a42dc9b759b3d26d13d60"
          }
        },
        "4d21ad34fe434f8e8fd1479eb6f6ddc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f614d9bd59e46ceaf614034d0c76ae6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:18&lt;00:00, 14.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdc70bbd46da44ceb23ea631efed5a9e"
          }
        },
        "1000130521cb4726b2943cacc6b4e3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dce0783e470a42dc9b759b3d26d13d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f614d9bd59e46ceaf614034d0c76ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdc70bbd46da44ceb23ea631efed5a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwarbabukm/Sentiment_Analysis_DistilBert/blob/main/DistilBert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkHcU4xabojz"
      },
      "source": [
        "# ***Sentiment Analysis using DistilBert on IMDB Movie Reviews***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbcldWRnbv1H"
      },
      "source": [
        "*Our goal is to create a model that takes a movie review and predicts if the particular review is positive or negative. DistilBERT processes the review and passes along some information it extracted from it on to the neural network classification model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. Itâ€™s a lighter and faster version of BERT that roughly matches its performance. The ML model will take in the result of DistilBERTâ€™s processing, and classify the review as either positive or negative sentiment.*\r\n",
        "\r\n",
        "*For DistillBERT, we use a model thatâ€™s already pre-trained and has a grasp on the English language. This model, however is neither trained not fine-tuned to do sentence classification.*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWIv1El76WzR",
        "outputId": "1ee071ee-2582-444c-f458-fc25e9f6dba6"
      },
      "source": [
        "!pip install transformers  #install transformer using pip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 19.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=77580a8c31b2feee8acf12d43d989329023dd6851b0757fd09f96911e05af79e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVKI7_TSb8Tw"
      },
      "source": [
        "## ***Reading the datasets containing the movie reviews and sentiments***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOa3Eb5Y6YTj",
        "outputId": "7d911712-524f-448c-aef6-1694f6945aa5"
      },
      "source": [
        "#Import Pandas and read excel file containing the movie reviews using pandas framework\r\n",
        "import pandas as pd\r\n",
        "train=df = pd.read_excel('/content/drive/MyDrive/train.xlsx') #training data\r\n",
        "test=df = pd.read_excel('/content/drive/MyDrive/test.xlsx') #test data\r\n",
        "train.shape, test.shape  #Provides the shape of imported dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 2), (25000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f439m48UHqxP",
        "outputId": "ce6bb65e-e27d-461b-ae84-32d0f9707ae7"
      },
      "source": [
        "train.dtypes #provides the data type of training dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews      object\n",
              "Sentiment     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLLW71-OID6Q",
        "outputId": "40145fd8-e804-4402-a5a1-3d36a66847bc"
      },
      "source": [
        "test.dtypes  #provides the data type of test dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reviews      object\n",
              "Sentiment     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Pj9hHGR16bda",
        "outputId": "e8c187a2-e672-4ae5-b1d1-21d266c6245c"
      },
      "source": [
        "train.head() #first 5 reviews and sentiments from the training data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I saw this film at the London Premiere, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What a bad, bad film!!! I can't believe all th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The photography on the DVD is so dark I though...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It seems a shame that Greta Garbo ended her il...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear me... Peter Sellers was one of the most o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Reviews  Sentiment\n",
              "0  I saw this film at the London Premiere, and I ...          0\n",
              "1  What a bad, bad film!!! I can't believe all th...          0\n",
              "2  The photography on the DVD is so dark I though...          0\n",
              "3  It seems a shame that Greta Garbo ended her il...          0\n",
              "4  Dear me... Peter Sellers was one of the most o...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EN7gLxvcWgk"
      },
      "source": [
        "train.tail() #last 5 reviews and sentiments from the training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWi-3gLhcdvo"
      },
      "source": [
        "*The sentiment is represented in numerical category where 0 is termed as negative sentiment and 1 is termed as positive sentiment.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1cqXPjg6gaC"
      },
      "source": [
        "def random_splitting(train,sample_size):\r\n",
        " train_data=train.sample(frac=sample_size) #randomly chooses the train data based on sample size\r\n",
        "                                            \r\n",
        " print('The shape of randomly picked data:',train_data.shape)                                         \r\n",
        " return train_data                                  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEViQw6Dc7pt"
      },
      "source": [
        "*random_splitting() function randomly picks 50% of the train data for the sentiment analysis. The fraction to split the data can be chosen as per our need. Here I have chosen sampling size to be 0.5 so that, it randomly chooses 50% of the train data.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1zK18Ba6iq5"
      },
      "source": [
        "#splitting the data into batches of 2500 rows each, for the smooth operation.\r\n",
        "def data_split(data,batches):\r\n",
        " n = batches  #batch size\r\n",
        "\r\n",
        " list_df = [data[i:i+n] for i in range(0,data.shape[0],n)] #Splits the data into batches\r\n",
        "\r\n",
        " [i.shape for i in list_df]\r\n",
        " return list_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtGqRvurdpBL"
      },
      "source": [
        "*data_split() function is used to split the datasets into batches before giving to DISTILBERT model. We have split the train data into 5 batches of 2500 each*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEq3Wv7zeBoJ"
      },
      "source": [
        "# ***DistilBert Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hvr21rf6kgr"
      },
      "source": [
        "#importing necessary packages required for running\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import transformers as trans\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adEA6-NMeFJw"
      },
      "source": [
        "***Initializing and Pre Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKcy5s5UqRKg"
      },
      "source": [
        "*Here DistilBert model is pretraining on the distilbert-base-uncased which means it does not make a difference between english and English.\r\n",
        "It has 6-layer, 768-hidden, 12-heads, 66M parameters.*\r\n",
        "\r\n",
        "*DistilBERT pretrained on the same data as BERT, which is BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia (excluding lists, tables and headers).*\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0-snQN06n9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "6d9ae97b01d54e8997d32c6896af9091",
            "3a5e0b7167e94cadad7e8d4a91631a4a",
            "54640b02220f428d97cbc59ec1c963b3",
            "6d1e47e965cc475ca3a110ecb3929f32",
            "4750650e23554a08a9bd03086ffad46d",
            "fb8962a4fed84bbbba3d8341931e31c3",
            "6a6619e55738480db54c616a4ede5d16",
            "eb69f336c3d242029754a1ed59d7131b",
            "4886ed8d25b449a48cf4b8304f196b0e",
            "545bbd06a0bc415ea33e7eb31ea66b20",
            "8c72ad7dad744654b4754f1dbae07165",
            "3e34be735492454f9bdceb42608540a3",
            "59941234d67d4c69b015b339f458964e",
            "75b871e233ff4f47b0ccc6314887760d",
            "00e6eca065a542a5a4827858bbe21502",
            "5629040d942e46cd96aafdb98e0cb2da",
            "3a13adf2f1e6427b87d570f10fe7de89",
            "ffd443a30f454ee1b3e7fd5487c3270f",
            "eed5ead0b8b14fc6bf1894dbcdb4f986",
            "4d21ad34fe434f8e8fd1479eb6f6ddc2",
            "1000130521cb4726b2943cacc6b4e3a9",
            "dce0783e470a42dc9b759b3d26d13d60",
            "2f614d9bd59e46ceaf614034d0c76ae6",
            "fdc70bbd46da44ceb23ea631efed5a9e"
          ]
        },
        "outputId": "68c5d27b-fc0d-4126-ead3-e56141ae42f6"
      },
      "source": [
        "#DistilBERT\r\n",
        "model_class, tokenizer_class, pretrained_weights = (trans.DistilBertModel, trans.DistilBertTokenizer, 'distilbert-base-uncased')\r\n",
        "\r\n",
        "# Load pretrained model and tokenizer\r\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\r\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d9ae97b01d54e8997d32c6896af9091",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4886ed8d25b449a48cf4b8304f196b0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a13adf2f1e6427b87d570f10fe7de89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1gnrn5neZV7"
      },
      "source": [
        "*The first step is to use the DISTILBERT tokenizer to split the word into tokens. Then, we add the special tokens needed for sentence classifications (these are [CLS] at the first position, and [SEP] at the end of the sentence).The next step the tokenizer does is to replace each token with its id from the embedding table which is a component we get with the trained model*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LnZWHJl6qPA"
      },
      "source": [
        "#Tokenization and Model running on the given datasets\r\n",
        "def DistilBert_model(list_df):\r\n",
        " count=0\r\n",
        " print('Status:')\r\n",
        " for df in list_df:  \r\n",
        "   count=count+1 \r\n",
        "   print('working on:',count,'set of data')\r\n",
        "   tokenized = df['Reviews'].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True,max_length=100,truncation=True)))\r\n",
        "   #had to restrict the max_length=100, as the system keeps on crashing on max_length greater than 100 \r\n",
        "  \r\n",
        "   #Padding\r\n",
        "   max_len = 0\r\n",
        "   for i in tokenized.values:\r\n",
        "      if len(i) > max_len:\r\n",
        "          max_len = len(i)\r\n",
        "   padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\r\n",
        "\r\n",
        "   input_ids = torch.tensor(padded)  #converting the tokens into tensors before inputting to DistilBert\r\n",
        " \r\n",
        "   with torch.no_grad():\r\n",
        "      last_hidden_states = model(input_ids)  #running DistilBert model on the converted tokens\r\n",
        "      feature= last_hidden_states[0][:,0,:].numpy() #Specially picks the CLS token from model\r\n",
        "   #for joining the batches into one single array for the machine learning model\r\n",
        "      if (count == 1):\r\n",
        "       features=feature\r\n",
        "      else:\r\n",
        "        data=np.append(features,feature,axis=0)\r\n",
        "        features=data\r\n",
        "\r\n",
        " return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMQWTFW8ep2V"
      },
      "source": [
        "*In this function, last_hidden_states holds the outputs of DistilBERT. It is a tuple with the shape (number of examples, max number of tokens in the sequence, number of hidden units in the DistilBERT model). In our case, this will be 12500 (since we only limited ourselves to 12500 examples), 100 (which is the number of tokens), 768 (the number of hidden units in the DistilBERT model).*\r\n",
        "\r\n",
        "*Because of the computational issues due to high datasets and feature size, I had to restrict the max_length of tokenizer model to be 100, as values above 100 led my colab to crash constantly.*\r\n",
        "\r\n",
        "*The output is a vector for each input token. each vector is made up of 768 numbers (floats). Because this is a sentence classification task, we ignore all except the first vector (the one associated with the [CLS] token). This is the vector we pass as the input to the neural network classification model.*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8COZTw7o6xWT"
      },
      "source": [
        "def train_test(X,Y):\r\n",
        " from sklearn.model_selection import train_test_split\r\n",
        " x_train,x_val,y_train,y_val=train_test_split(X,Y,test_size=0.2)\r\n",
        " x_train.shape,x_val.shape #shape after splitting the data\r\n",
        " return x_train,x_val,y_train,y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkViXgg1fUE-"
      },
      "source": [
        "*train_test() function is used to split the data into train and validation set on a given specific size*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fdmc0lKTyzR"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers \r\n",
        "\r\n",
        "def model_fit(x_train,x_val,y_train,y_val):\r\n",
        " base_model = models.Sequential()\r\n",
        " base_model.add(layers.Dense(64, activation='relu', input_dim=768))\r\n",
        " base_model.add(layers.Dense(64, activation='relu'))\r\n",
        " base_model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        " print(base_model.summary())\r\n",
        " base_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\r\n",
        " base_model.fit(x_train\r\n",
        "                       , y_train\r\n",
        "                       , epochs=20                     \r\n",
        "                       , batch_size=5\r\n",
        "                       , validation_data=(x_val,y_val)\r\n",
        "                       , verbose=1)\r\n",
        " return base_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsCnlp2Tfjwq"
      },
      "source": [
        "*model_fit() is used to initialize and train the neural model on the training dataset and outputs the prediction accuracy of the model on validation dataset.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1KBxghL64WQ",
        "outputId": "66423f77-1783-4a96-d257-3fd7a5831b08"
      },
      "source": [
        "frac=0.5 \r\n",
        "print('Randomly picked',100*frac,'% data')\r\n",
        "train_data = random_splitting(train,frac) #randomly picking 30% of the train data = 7.5k datasets\r\n",
        "batch_size=2500\r\n",
        "list_df= data_split(train_data,batch_size) #splitting total of 7.5k datasets into 3 batches of 2.5k datas\r\n",
        "print('Split the data into',int(len(train_data)/batch_size),'batches of',batch_size,'each')\r\n",
        "features= DistilBert_model(list_df) #running tokenization and distilbert model on the datasets\r\n",
        "print('DistilBert was succesfully run on the full datasets')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomly picked 50.0 % data\n",
            "The shape of randomly picked data: (12500, 2)\n",
            "Split the data into 5 batches of 2500 each\n",
            "Status:\n",
            "working on: 1 set of data\n",
            "working on: 2 set of data\n",
            "working on: 3 set of data\n",
            "working on: 4 set of data\n",
            "working on: 5 set of data\n",
            "DistilBert was succesfully run on the full datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvcsPeSiUaFB"
      },
      "source": [
        "train_data['Sentiment'].head()\r\n",
        "labels=train_data['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oXuBQD4j-I1",
        "outputId": "9bbb025e-5e17-4ba5-905c-86025a85490f"
      },
      "source": [
        "labels[:5,]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9479     0\n",
              "13173    1\n",
              "12585    1\n",
              "18821    0\n",
              "7452     0\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zObRupjDY_5y"
      },
      "source": [
        "***Choosing the test data for prediction***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNkf9CQk7DWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a173ed8a-beaf-4684-a26c-34b38b6dad1e"
      },
      "source": [
        "frac= 0.2\r\n",
        "test_data = random_splitting(test,frac) #randomly picking 20% of the test data for prediction\r\n",
        "print('Randomly picked',100*frac,'% data')\r\n",
        "batch=2500\r\n",
        "list_tdf= data_split(test_data,batch) #split into batches\r\n",
        "print('Split the data into',int(len(test_data)/batch),'batches')\r\n",
        "x_test= DistilBert_model(list_tdf) #running tokenization and distilbert model on the datasets\r\n",
        "print('DistilBert was succesfully run on the full datasets')\r\n",
        "y_test=test_data['Sentiment']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of randomly picked data: (5000, 2)\n",
            "Randomly picked 20.0 % data\n",
            "Split the data into 2 batches\n",
            "Status:\n",
            "working on: 1 set of data\n",
            "working on: 2 set of data\n",
            "DistilBert was succesfully run on the full datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl2CroDgZHvk"
      },
      "source": [
        "***Data splitting and training of the neural network***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWl4ykLRVzfa",
        "outputId": "5d60e4df-7594-4a58-edc8-1a81f361964f"
      },
      "source": [
        " x_train,x_val,y_train,y_val = train_test(features,labels)\r\n",
        " print('Train data shape:',x_train.shape,', Validation data shape:',x_val.shape)\r\n",
        " base_model = model_fit(x_train,x_val,y_train,y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape: (10000, 768) , Validation data shape: (2500, 768)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 64)                49216     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 53,441\n",
            "Trainable params: 53,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.4962 - acc: 0.7580 - val_loss: 0.4722 - val_acc: 0.7820\n",
            "Epoch 2/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4591 - acc: 0.7841 - val_loss: 0.5315 - val_acc: 0.7580\n",
            "Epoch 3/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4471 - acc: 0.7899 - val_loss: 0.4603 - val_acc: 0.7808\n",
            "Epoch 4/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4377 - acc: 0.7954 - val_loss: 0.4543 - val_acc: 0.7824\n",
            "Epoch 5/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4321 - acc: 0.7970 - val_loss: 0.4761 - val_acc: 0.7804\n",
            "Epoch 6/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4270 - acc: 0.8023 - val_loss: 0.4621 - val_acc: 0.7804\n",
            "Epoch 7/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4246 - acc: 0.8001 - val_loss: 0.4495 - val_acc: 0.7892\n",
            "Epoch 8/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.4160 - acc: 0.8083 - val_loss: 0.4514 - val_acc: 0.7936\n",
            "Epoch 9/20\n",
            "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4116 - acc: 0.8073 - val_loss: 0.4639 - val_acc: 0.7800\n",
            "Epoch 10/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.4053 - acc: 0.8116 - val_loss: 0.4607 - val_acc: 0.7864\n",
            "Epoch 11/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4013 - acc: 0.8130 - val_loss: 0.5027 - val_acc: 0.7756\n",
            "Epoch 12/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3962 - acc: 0.8156 - val_loss: 0.4726 - val_acc: 0.7856\n",
            "Epoch 13/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3899 - acc: 0.8163 - val_loss: 0.4602 - val_acc: 0.7880\n",
            "Epoch 14/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.3866 - acc: 0.8208 - val_loss: 0.4893 - val_acc: 0.7832\n",
            "Epoch 15/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.3816 - acc: 0.8202 - val_loss: 0.4712 - val_acc: 0.7924\n",
            "Epoch 16/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.3764 - acc: 0.8269 - val_loss: 0.4985 - val_acc: 0.7700\n",
            "Epoch 17/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.3719 - acc: 0.8245 - val_loss: 0.4943 - val_acc: 0.7972\n",
            "Epoch 18/20\n",
            "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3684 - acc: 0.8286 - val_loss: 0.4705 - val_acc: 0.7920\n",
            "Epoch 19/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.3632 - acc: 0.8323 - val_loss: 0.4756 - val_acc: 0.7860\n",
            "Epoch 20/20\n",
            "2000/2000 [==============================] - 3s 2ms/step - loss: 0.3597 - acc: 0.8325 - val_loss: 0.4856 - val_acc: 0.7920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HL411JyZiW7"
      },
      "source": [
        "***Prediction on test datasets***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA5u9kEu7Fj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d85cd4-8093-4477-c48c-d6107bb491c4"
      },
      "source": [
        "y_pred=base_model.predict_classes(x_test,batch_size=1,verbose=1)\r\n",
        "#prediction on the test datasets."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 3s 688us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkTsBmjmZpnC"
      },
      "source": [
        "***Performance metrics of the classification model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1WpIR8ri2bI",
        "outputId": "f52244dd-7dc5-49b7-f042-fd6cb65933e5"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.72      0.77      2470\n",
            "           1       0.76      0.84      0.79      2530\n",
            "\n",
            "    accuracy                           0.78      5000\n",
            "   macro avg       0.78      0.78      0.78      5000\n",
            "weighted avg       0.78      0.78      0.78      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvpSyaanlAPe",
        "outputId": "7e5e2153-2e3a-4a57-b4cd-64af57f41324"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "accu= accuracy_score(y_test,y_pred)\r\n",
        "print('The Accuracy on test data is:',accu*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Accuracy on test data is: 78.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg3ie0K7Z-ME"
      },
      "source": [
        "*The neural network predicted the test data with an accuracy of 78.08%. The model was trained on 12.5k train datasets and predicted the sentiment on 5k randomly selected test data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zO1y6SFf77B"
      },
      "source": [
        "# ***EDA - Easy Data Augmentation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvS1qh-mv1TS"
      },
      "source": [
        "*EDA (Easy Data Augmentation) is a set of techniques for boosting performance on textclassification tasks. EDA consists of four simple but powerful operations: 1) synonym replacement 2) random insertion 3) random swap 4) random deletion. On five text classification tasks, It shows that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets, on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkNlFQPB7HZy"
      },
      "source": [
        "#Applying EDA - Easy Data Augmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLYTKmvg7J-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba396bc6-20a6-48ea-837e-be68514395f4"
      },
      "source": [
        "!pip install numpy nltk gensim textblob googletrans\r\n",
        "import nltk \r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('stopwords')\r\n",
        "!pip install textaugment"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.0.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.12.5)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/3c/cdeaf9ab0404853e77c45d9e8021d0d2c01f70a1bb26e460090926fe2a5e/hstspreload-2020.11.21-py3-none-any.whl (981kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 983kB 8.8MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 6.9MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.4MB/s \n",
            "\u001b[?25hCollecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 9.9MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-cp36-none-any.whl size=15737 sha256=a83ad5580d4be93631aea3159ca3ace1dd5db55bb6127885ffdc9fd52b8cbae9\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=62e3bf2bee5a226a2398b273cf2771a47a135b5a66e36e850ed95275afd599da\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: immutables, contextvars, sniffio, hstspreload, rfc3986, hpack, hyperframe, h2, h11, httpcore, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.11.21 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.2.0\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting textaugment\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/63/9960414280dba3d9eba332502231d69fdc8ba664a4bd3d46842ba8cf0ef2/textaugment-1.3.4-py3-none-any.whl\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from textaugment) (0.15.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from textaugment) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from textaugment) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from textaugment) (1.18.5)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (from textaugment) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->textaugment) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->textaugment) (4.0.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->textaugment) (1.15.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.6/dist-packages (from googletrans->textaugment) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (2020.12.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (1.2.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (3.0.4)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (0.9.1)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (2.10)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (2020.11.21)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans->textaugment) (1.4.0)\n",
            "Requirement already satisfied: contextvars>=2.1; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from sniffio->httpx==0.13.3->googletrans->textaugment) (2.4)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans->textaugment) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans->textaugment) (3.2.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars>=2.1; python_version < \"3.7\"->sniffio->httpx==0.13.3->googletrans->textaugment) (0.14)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans->textaugment) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans->textaugment) (5.2.0)\n",
            "Installing collected packages: textaugment\n",
            "Successfully installed textaugment-1.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-UAKnCj7ND2"
      },
      "source": [
        "from textaugment import EDA\r\n",
        "t=EDA()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMdCCGZFv9rG"
      },
      "source": [
        "*EDA is imported from the text augment. And called to a object.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Z9wm2KwHbn"
      },
      "source": [
        "### ***Examples of Easy Data Augmentation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCmack2C7Orl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d270d2a6-4dd3-4a28-fccb-21339e2f7bde"
      },
      "source": [
        "t.random_insertion('Movie is awesome, And it needs some improvemnt in cinematography')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Movie is awesome, And film it needs some improvemnt in cinematography'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8myR98iXVOTu"
      },
      "source": [
        "*It inserts a random synonym of a random word in the sentence that is not a stop word. Insert that synonym into a random position in the sentence. In this case the synonym of word 'movie' is created, which is 'film', and inserted into the sentence.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI5Cjl947QrN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "39fb6de6-a8f0-4c11-8c8d-636234aa086f"
      },
      "source": [
        "t.random_deletion('film was not upto the expectation and expected a lot from such a great director')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'film was not upto the expectation and expected from such a director'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4anWndvW1Ky"
      },
      "source": [
        "*Randomly  remove each word in the sentence with probability p. Here two words are omitted from the sentence which are 'a' and 'lot'.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n2YWPTr7S3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f2e70453-ae8f-461a-e2d7-5aeeaf7419f4"
      },
      "source": [
        "t.random_swap('the best movie experience till date. No words to express the cinematography')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'date. best movie experience till the No words to express the cinematography'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLEGJv9qYO2G"
      },
      "source": [
        "*Randomly  choose  two words in the sentence and swap their positions. \r\n",
        "The words 'Date' and 'The' are swapped in this sentence.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grtqiMgn7UrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1170ba62-080c-483a-c4db-022e851ec54f"
      },
      "source": [
        "t.synonym_replacement('movie is okayish. The acting was good but needs improvement')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'flick is okayish. The acting was good but needs improvement'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejlxEO_eYi8E"
      },
      "source": [
        "*Randomly choose n words from the sentence that are not stop words.  Replace each of these words withone of its synonyms chosen at random. In the above sentence the word 'movie' is replaced by its synonym 'flick'.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBFBQnda7WVw"
      },
      "source": [
        "def data_augmentation(train):\r\n",
        " train1=[]\r\n",
        " label1=[]\r\n",
        " train=train.sample(frac=0.5)\r\n",
        " for i in range(0,6250):\r\n",
        "   train1.append(t.random_insertion(train.iloc[i,0]))\r\n",
        "   train1.append(t.random_deletion(train.iloc[i,0]))\r\n",
        "   train1.append(t.random_swap(train.iloc[i,0]))\r\n",
        "   train1.append(t.synonym_replacement(train.iloc[i,0]))\r\n",
        "   for j in range(4):\r\n",
        "    if train.iloc[i,1]==0:\r\n",
        "      label1.append(0)\r\n",
        "    else:\r\n",
        "      label1.append(1)\r\n",
        " return train1,label1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8krDHeExQfH"
      },
      "source": [
        "*data_augmentation() function is used for Easy Data Augmentation process. We randomly chose 50% of the selected training data and applied four different processes of EDA to it. Thus 25000 new datasets are formed after the application of EDA and appended to the original 12.5k datasets.*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63LUefGO7YpO"
      },
      "source": [
        "def to_df(trains,labels_data):\r\n",
        "  train=np.array(trains) #the reviews are converted to array\r\n",
        "  train.reshape(-1,1)\r\n",
        "  label=np.array(labels_data) #sentiments are converted to array\r\n",
        "  label.reshape(-1,1)\r\n",
        "  arr = np.column_stack((train,label)) #joined the review column and sentiment column\r\n",
        "  train=pd.DataFrame(arr,columns=['Reviews','Sentiment']) #the array of reviews and sentiment are converted to dataframe\r\n",
        "  train=train.reset_index(drop=True) \r\n",
        "  print('The shape of dataset which contain only EDA applied reviews:->', train.shape) #shape of newly formed datasets\r\n",
        "  return train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SijoCIBCyfw4"
      },
      "source": [
        "*to_df() function is used to convert those newly formed EDA applied datasets into a dataframe.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eog7frO57a_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc77558-94ec-4eb6-dbee-739cd6e82957"
      },
      "source": [
        "train_EDA,label_EDA=data_augmentation(train_data) #EDA process is done using this function\r\n",
        "t_data=to_df(train_EDA,label_EDA) #converts the EDA applied datasets into dataframe\r\n",
        "train_data_EDA=train_data.append(t_data,sort=False) #both original datasets and EDA applied datasets are merged.\r\n",
        "train_data_EDA=train_data_EDA.sample(frac=1) #shuffling is done\r\n",
        "print('After applying EDA methods the total dataset for the model is increased to ->',train_data_EDA.shape)\r\n",
        "batches=2500 \r\n",
        "list_df= data_split(train_data_EDA,batches) #The whole dataset is split into number of batcges of certain size. We have chosen 2500 as the batch size.\r\n",
        "print('Split the data into',int(len(train_data_EDA)/batches),'batches')\r\n",
        "features= DistilBert_model(list_df) #running tokenization and distilbert model on the datasets\r\n",
        "print('Finished....')\r\n",
        "print('DistilBert was succesfully run on the full datasets')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of dataset which contain only EDA applied reviews:-> (25000, 2)\n",
            "After applying EDA methods the total dataset for the model is increased to -> (37500, 2)\n",
            "Split the data into 15 batches\n",
            "Status:\n",
            "working on: 1 set of data\n",
            "working on: 2 set of data\n",
            "working on: 3 set of data\n",
            "working on: 4 set of data\n",
            "working on: 5 set of data\n",
            "working on: 6 set of data\n",
            "working on: 7 set of data\n",
            "working on: 8 set of data\n",
            "working on: 9 set of data\n",
            "working on: 10 set of data\n",
            "working on: 11 set of data\n",
            "working on: 12 set of data\n",
            "working on: 13 set of data\n",
            "working on: 14 set of data\n",
            "working on: 15 set of data\n",
            "Finished....\n",
            "DistilBert was succesfully run on the full datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPKqk4dMPnS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d16c4e3-5713-47ac-ec34-5447c68a030f"
      },
      "source": [
        " train_data_EDA['Sentiment'].dtypes #checking the data type of Sentiment column"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSqSSP7WJCxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff4e57b-2fd2-4e84-da47-66f8fd0a35c2"
      },
      "source": [
        "labels_eda=train_data_EDA['Sentiment'].astype('int64') #as the data type of Sentiment column is Object, We convert it to 'int64' for the neural network\r\n",
        "labels_eda.shape, labels_eda.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500,), dtype('int64'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkiwzINA41jo"
      },
      "source": [
        "### ***Training and prediction after applying EDA***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6f2vWfVZQSS",
        "outputId": "7ea3b28f-4d08-4bd2-edc2-38b528620170"
      },
      "source": [
        " x_train,x_val,y_train,y_val = train_test(features,labels_eda) #The datasets are split into train and validation set.\r\n",
        " base_model = model_fit(x_train,x_val,y_train,y_val) #neural network"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 64)                49216     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 53,441\n",
            "Trainable params: 53,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 0.4692 - acc: 0.7766 - val_loss: 0.4511 - val_acc: 0.7844\n",
            "Epoch 2/20\n",
            "6000/6000 [==============================] - 9s 1ms/step - loss: 0.4353 - acc: 0.7954 - val_loss: 0.4367 - val_acc: 0.7929\n",
            "Epoch 3/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.4226 - acc: 0.8035 - val_loss: 0.4237 - val_acc: 0.7971\n",
            "Epoch 4/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.4046 - acc: 0.8136 - val_loss: 0.4100 - val_acc: 0.8049\n",
            "Epoch 5/20\n",
            "6000/6000 [==============================] - 9s 1ms/step - loss: 0.3878 - acc: 0.8212 - val_loss: 0.4022 - val_acc: 0.8112\n",
            "Epoch 6/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.3764 - acc: 0.8270 - val_loss: 0.3967 - val_acc: 0.8180\n",
            "Epoch 7/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.3618 - acc: 0.8363 - val_loss: 0.3870 - val_acc: 0.8191\n",
            "Epoch 8/20\n",
            "6000/6000 [==============================] - 9s 1ms/step - loss: 0.3522 - acc: 0.8418 - val_loss: 0.3947 - val_acc: 0.8191\n",
            "Epoch 9/20\n",
            "6000/6000 [==============================] - 9s 1ms/step - loss: 0.3395 - acc: 0.8493 - val_loss: 0.3742 - val_acc: 0.8283\n",
            "Epoch 10/20\n",
            "6000/6000 [==============================] - 10s 2ms/step - loss: 0.3280 - acc: 0.8545 - val_loss: 0.4461 - val_acc: 0.7943\n",
            "Epoch 11/20\n",
            "6000/6000 [==============================] - 10s 2ms/step - loss: 0.3208 - acc: 0.8585 - val_loss: 0.3707 - val_acc: 0.8284\n",
            "Epoch 12/20\n",
            "6000/6000 [==============================] - 9s 1ms/step - loss: 0.3087 - acc: 0.8643 - val_loss: 0.3896 - val_acc: 0.8280\n",
            "Epoch 13/20\n",
            "6000/6000 [==============================] - 10s 2ms/step - loss: 0.3017 - acc: 0.8675 - val_loss: 0.3573 - val_acc: 0.8427\n",
            "Epoch 14/20\n",
            "6000/6000 [==============================] - 10s 2ms/step - loss: 0.2947 - acc: 0.8715 - val_loss: 0.3579 - val_acc: 0.8351\n",
            "Epoch 15/20\n",
            "6000/6000 [==============================] - 9s 1ms/step - loss: 0.2876 - acc: 0.8736 - val_loss: 0.3660 - val_acc: 0.8403\n",
            "Epoch 16/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.2796 - acc: 0.8798 - val_loss: 0.3734 - val_acc: 0.8365\n",
            "Epoch 17/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.2737 - acc: 0.8838 - val_loss: 0.3708 - val_acc: 0.8487\n",
            "Epoch 18/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.2671 - acc: 0.8853 - val_loss: 0.3471 - val_acc: 0.8516\n",
            "Epoch 19/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.2612 - acc: 0.8884 - val_loss: 0.4531 - val_acc: 0.8169\n",
            "Epoch 20/20\n",
            "6000/6000 [==============================] - 9s 2ms/step - loss: 0.2566 - acc: 0.8912 - val_loss: 0.3371 - val_acc: 0.8593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBc6IksN5BbV"
      },
      "source": [
        "*Prediction on the same set of test data which was used before the application of EDA. So the model performance can easily be distinguished as with and without applying EDA.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BwEBSW1ZVQR"
      },
      "source": [
        "***The performance metrics of the model after applying EDA***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFEbQIJi4jY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009b5310-555f-430e-ba4e-0f7edb8ee852"
      },
      "source": [
        "y_pred=base_model.predict_classes(x_test,batch_size=1,verbose=1)\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 4s 710us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.71      0.74      2470\n",
            "           1       0.74      0.81      0.77      2530\n",
            "\n",
            "    accuracy                           0.76      5000\n",
            "   macro avg       0.76      0.76      0.76      5000\n",
            "weighted avg       0.76      0.76      0.76      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-h_n1FE5nbh"
      },
      "source": [
        "\r\n",
        "*The Model performance on the test data before the application of EDA is : 78.08%*\r\n",
        "\r\n",
        "*The Model performance on the test data after the application of EDA is: 76%*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spCuMjIiAC7k"
      },
      "source": [
        "*Based on the model performance, the accuracy have fallen down after applying the EDA techniques. The model has overfitted the data which caused to decrease the performance in terms of precision,recall and accuracy.* \r\n",
        "\r\n",
        "*As I had the plan to use CNN model in this particular task, the colab was crashing due to high computational requirement on the datasets. So moved up with neural network and noted the accuracy before and after applying the EDA.*"
      ]
    }
  ]
}