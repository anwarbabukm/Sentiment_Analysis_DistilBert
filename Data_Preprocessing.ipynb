{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcon62GfGSud"
      },
      "source": [
        "# ***Preprocessing Raw Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Nc6auoGiNu"
      },
      "source": [
        "*Firstly we need to import shutil library which could help to extract the datas from .tar.gz type compressed file. Then we extract it to a specific folder in google drive for the later use.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJkTksvTVEce"
      },
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/aclImdb_v1.tar.gz\", \"/content/drive/MyDrive/IMDB FILE\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1uvScHaG6Th"
      },
      "source": [
        "*After the extraction the data is collected in IMDB FILE directory in google drive. It consists of two folders of train and test data, in which the datas are differentiatetd into folders based on the sentiment. So we need to preprocess the raw datas and make it into 25k train and test data each.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3V4-im3VNBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975855ea-8aea-4135-f970-bd79630b54ea"
      },
      "source": [
        "import os\n",
        "import pickle as pk\n",
        "\n",
        "imdb_dir = '/content/drive/MyDrive/IMDB FILE/aclImdb'  #directory from where the datas are picked for preprocessing\n",
        "labels = list()\n",
        "texts = list()\n",
        "for kind in ['train','test']:\n",
        " print(kind,'Loading...')\n",
        " data_dir = os.path.join(imdb_dir, kind)\n",
        " # Processing the labels of the raw IMDB data\n",
        " for label_type in ['neg', 'pos']:\n",
        "     count=0\n",
        "     print(label_type,'Loading...')\n",
        "     dir_name = os.path.join(data_dir, label_type)\n",
        "     for fname in os.listdir(dir_name):\n",
        "         count=count+1\n",
        "         if (count%500)==0:\n",
        "           print(count,'finished')\n",
        "         if fname[-4:] == '.txt':\n",
        "             f = open(os.path.join(dir_name, fname),encoding=\"utf8\")\n",
        "             texts.append(f.read())\n",
        "             f.close()\n",
        "             if label_type == 'neg':\n",
        "                 labels.append(0)\n",
        "             else:\n",
        "                 labels.append(1)\n",
        "                "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train Loading...\n",
            "neg Loading...\n",
            "500 finished\n",
            "1000 finished\n",
            "1500 finished\n",
            "2000 finished\n",
            "2500 finished\n",
            "3000 finished\n",
            "3500 finished\n",
            "4000 finished\n",
            "4500 finished\n",
            "5000 finished\n",
            "5500 finished\n",
            "6000 finished\n",
            "6500 finished\n",
            "7000 finished\n",
            "7500 finished\n",
            "8000 finished\n",
            "8500 finished\n",
            "9000 finished\n",
            "9500 finished\n",
            "10000 finished\n",
            "10500 finished\n",
            "11000 finished\n",
            "11500 finished\n",
            "12000 finished\n",
            "12500 finished\n",
            "pos Loading...\n",
            "500 finished\n",
            "1000 finished\n",
            "1500 finished\n",
            "2000 finished\n",
            "2500 finished\n",
            "3000 finished\n",
            "3500 finished\n",
            "4000 finished\n",
            "4500 finished\n",
            "5000 finished\n",
            "5500 finished\n",
            "6000 finished\n",
            "6500 finished\n",
            "7000 finished\n",
            "7500 finished\n",
            "8000 finished\n",
            "8500 finished\n",
            "9000 finished\n",
            "9500 finished\n",
            "10000 finished\n",
            "10500 finished\n",
            "11000 finished\n",
            "11500 finished\n",
            "12000 finished\n",
            "12500 finished\n",
            "test Loading...\n",
            "neg Loading...\n",
            "500 finished\n",
            "1000 finished\n",
            "1500 finished\n",
            "2000 finished\n",
            "2500 finished\n",
            "3000 finished\n",
            "3500 finished\n",
            "4000 finished\n",
            "4500 finished\n",
            "5000 finished\n",
            "5500 finished\n",
            "6000 finished\n",
            "6500 finished\n",
            "7000 finished\n",
            "7500 finished\n",
            "8000 finished\n",
            "8500 finished\n",
            "9000 finished\n",
            "9500 finished\n",
            "10000 finished\n",
            "10500 finished\n",
            "11000 finished\n",
            "11500 finished\n",
            "12000 finished\n",
            "12500 finished\n",
            "pos Loading...\n",
            "500 finished\n",
            "1000 finished\n",
            "1500 finished\n",
            "2000 finished\n",
            "2500 finished\n",
            "3000 finished\n",
            "3500 finished\n",
            "4000 finished\n",
            "4500 finished\n",
            "5000 finished\n",
            "5500 finished\n",
            "6000 finished\n",
            "6500 finished\n",
            "7000 finished\n",
            "7500 finished\n",
            "8000 finished\n",
            "8500 finished\n",
            "9000 finished\n",
            "9500 finished\n",
            "10000 finished\n",
            "10500 finished\n",
            "11000 finished\n",
            "11500 finished\n",
            "12000 finished\n",
            "12500 finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWfiYGfrH8eb"
      },
      "source": [
        "*This is a simple function to convert the list of texts and labels into a DataFrame which can later be converted to an excel file for further use.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HodPqnUrkbz"
      },
      "source": [
        "def to_df(texts,labels):\n",
        "  texts=np.array(texts)\n",
        "  texts.reshape(-1,1)\n",
        "  label=np.array(labels)\n",
        "  label.reshape(-1,1)\n",
        "  arr = np.column_stack((texts,label))\n",
        "  texts=pd.DataFrame(arr,columns=['Reviews','Sentiment'])\n",
        "  texts=texts.reset_index(drop=True)\n",
        "  print('The shape of dataset :->', texts.shape)\n",
        "  return texts"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xNTeZgJuPgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88db676-113c-4dc4-907f-27b2a1802474"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data=to_df(texts,labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of dataset which contain only EDA applied reviews:-> (50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njj_LA1OIRGH"
      },
      "source": [
        "*We have preprocessed the raw datas into reviews and sentiment columns. This consists of 50k datas of both train and test set. So we need to split the dataframe into train and test set of 25k each.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YkBSCEBr7s8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5021da-a99d-4515-ab1f-ff0bac9f2a77"
      },
      "source": [
        "train=data.iloc[0:25000] #first 25k consists of the train data\n",
        "test=data.iloc[25000:50000] #next set of 25k consists of the test data\n",
        "train.shape,test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 2), (25000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j4HzTi2jCPRP",
        "outputId": "d6a2a9f0-1941-4805-defe-e6b55ffa95bc"
      },
      "source": [
        "train=train.sample(frac=1) #data is shuffled before converting to excel file\r\n",
        "train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>I saw this film at the London Premiere, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1132</th>\n",
              "      <td>What a bad, bad film!!! I can't believe all th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5504</th>\n",
              "      <td>The photography on the DVD is so dark I though...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9014</th>\n",
              "      <td>It seems a shame that Greta Garbo ended her il...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2679</th>\n",
              "      <td>Dear me... Peter Sellers was one of the most o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Reviews Sentiment\n",
              "592   I saw this film at the London Premiere, and I ...         0\n",
              "1132  What a bad, bad film!!! I can't believe all th...         0\n",
              "5504  The photography on the DVD is so dark I though...         0\n",
              "9014  It seems a shame that Greta Garbo ended her il...         0\n",
              "2679  Dear me... Peter Sellers was one of the most o...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QeZkgcseCSDh",
        "outputId": "4111eae2-7349-45a0-e011-f0f885758604"
      },
      "source": [
        "test=test.sample(frac=1) #data is shuffled before converting to excel file\r\n",
        "train.head()\r\n",
        "test.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43386</th>\n",
              "      <td>This film had some very funny moments. The afo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35219</th>\n",
              "      <td>Natalie Wood portrays Courtney Patterson, a po...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45295</th>\n",
              "      <td>I saw this movie when I was a kid and have bee...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42895</th>\n",
              "      <td>I just saw this movie for the first time last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30911</th>\n",
              "      <td>Hunk of trash only the Full Moon Studios could...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Reviews Sentiment\n",
              "43386  This film had some very funny moments. The afo...         1\n",
              "35219  Natalie Wood portrays Courtney Patterson, a po...         0\n",
              "45295  I saw this movie when I was a kid and have bee...         1\n",
              "42895  I just saw this movie for the first time last ...         1\n",
              "30911  Hunk of trash only the Full Moon Studios could...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEykZxrXJSrJ"
      },
      "source": [
        "*The dataframe of both train and test data is converted to excel file of format .xlsx. This data is saved to a directory in google drive.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB5F8hpGAE42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f759940-d226-457d-9a78-e8bc92dab527"
      },
      "source": [
        "!pip install xlsxwriter\r\n",
        "import xlsxwriter\r\n",
        "train.to_excel(r'/content/drive/MyDrive/IMDB FILE/train.xlsx',index=False,engine='xlsxwriter')\r\n",
        "test.to_excel(r'/content/drive/MyDrive/IMDB FILE/test.xlsx',index=False,engine='xlsxwriter')\r\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/41/bf1aae04932d1eaffee1fc5f8b38ca47bbbf07d765129539bc4bcce1ce0c/XlsxWriter-1.3.7-py2.py3-none-any.whl (144kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 102kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 112kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 122kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 133kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 143kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 5.4MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}